INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - ðŸ‘‹ Welcome to genai-bench 0.0.2! I am an intelligent benchmark tool for Large Language Model.
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - Options you provided:
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - num_concurrency: (1, 2, 4, 8, 16, 32, 64, 128, 256)
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - batch_size: [1]
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - api_backend: sglang
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - api_base: http://localhost:8000
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - api_key: xxx
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - api_model_name: openai/gpt-oss-20b
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - model_tokenizer: /root/spark-dev-workspace/dev/trtllm-bench/tiktoken
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - task: text-to-text
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - max_time_per_run: 30
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - max_requests_per_run: 10
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - additional_request_params: {}
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - gcp_credentials_path: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - gcp_location: us-central1
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - gcp_project_id: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - azure_ad_token: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - azure_api_version: 2024-02-01
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - azure_deployment: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - azure_endpoint: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - aws_region: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - aws_profile: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - aws_session_token: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - aws_secret_access_key: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - aws_access_key_id: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - model_api_key: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - model_auth_type: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - region: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - security_token: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - profile: DEFAULT
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - config_file: ~/.oci/config
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - auth: user_principal
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - server_engine: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - server_version: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - server_gpu_type: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - server_gpu_count: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - model: tiktoken
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - iteration_type: num_concurrency
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - traffic_scenario: ['N(480,240)/(300,150)', 'D(100,100)', 'D(100,1000)', 'D(2000,200)', 'D(7800,200)']
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - experiment_base_dir: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - experiment_folder_name: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - dataset_path: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - dataset_prompt_column: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - dataset_image_column: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - dataset_config: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - spawn_rate: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - num_workers: 0
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - master_port: 5557
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - upload_results: False
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - namespace: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - github_repo: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - github_owner: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - github_token: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - storage_gcp_credentials_path: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - storage_gcp_project_id: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - storage_azure_sas_token: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - storage_azure_connection_string: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - storage_azure_account_key: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - storage_azure_account_name: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - storage_aws_profile: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - storage_aws_region: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - storage_aws_session_token: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - storage_aws_secret_access_key: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - storage_aws_access_key_id: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - storage_auth_type: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - storage_prefix: 
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - storage_bucket: None
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - storage_provider: oci
INFO     2025-12-02 15:17:58.%f - genai_bench.benchmark:benchmark - Using sglang authentication
ERROR    2025-12-02 15:17:58.%f - root:handle_uncaught_exception - Uncaught exception
Traceback (most recent call last):
  File "/home/mtkuser/spark-dev-workspace/infer-bench/bin/genai-bench", line 10, in <module>
    sys.exit(cli())
             ^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
         ^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/core.py", line 1697, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/decorators.py", line 33, in new_func
    return f(get_current_context(), *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/genai_bench/cli/cli.py", line 259, in benchmark
    tokenizer = validate_tokenizer(model_tokenizer)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/genai_bench/cli/validation.py", line 157, in validate_tokenizer
    if isinstance(model_tokenizer, str) and Path(model_tokenizer).exists():
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/pathlib.py", line 862, in exists
    self.stat(follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.12/pathlib.py", line 842, in stat
    return os.stat(self, follow_symlinks=follow_symlinks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
PermissionError: [Errno 13] Permission denied: '/root/spark-dev-workspace/dev/trtllm-bench/tiktoken'
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - ðŸ‘‹ Welcome to genai-bench 0.0.2! I am an intelligent benchmark tool for Large Language Model.
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - Options you provided:
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - num_concurrency: (1, 2, 4, 8, 16, 32, 64, 128, 256)
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - batch_size: [1]
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - api_backend: sglang
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - api_base: http://localhost:8000
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - api_key: xxx
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - api_model_name: openai/gpt-oss-20b
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - model_tokenizer: /home/mtkuser/spark-dev-workspace/dev/trtllm-bench/tiktoken
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - task: text-to-text
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - max_time_per_run: 30
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - max_requests_per_run: 10
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - additional_request_params: {}
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - gcp_credentials_path: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - gcp_location: us-central1
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - gcp_project_id: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - azure_ad_token: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - azure_api_version: 2024-02-01
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - azure_deployment: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - azure_endpoint: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - aws_region: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - aws_profile: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - aws_session_token: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - aws_secret_access_key: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - aws_access_key_id: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - model_api_key: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - model_auth_type: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - region: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - security_token: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - profile: DEFAULT
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - config_file: ~/.oci/config
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - auth: user_principal
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - server_engine: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - server_version: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - server_gpu_type: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - server_gpu_count: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - model: tiktoken
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - iteration_type: num_concurrency
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - traffic_scenario: ['N(480,240)/(300,150)', 'D(100,100)', 'D(100,1000)', 'D(2000,200)', 'D(7800,200)']
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - experiment_base_dir: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - experiment_folder_name: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - dataset_path: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - dataset_prompt_column: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - dataset_image_column: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - dataset_config: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - spawn_rate: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - num_workers: 0
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - master_port: 5557
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - upload_results: False
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - namespace: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - github_repo: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - github_owner: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - github_token: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - storage_gcp_credentials_path: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - storage_gcp_project_id: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - storage_azure_sas_token: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - storage_azure_connection_string: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - storage_azure_account_key: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - storage_azure_account_name: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - storage_aws_profile: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - storage_aws_region: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - storage_aws_session_token: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - storage_aws_secret_access_key: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - storage_aws_access_key_id: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - storage_auth_type: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - storage_prefix: 
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - storage_bucket: None
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - storage_provider: oci
INFO     2025-12-02 15:18:22.%f - genai_bench.benchmark:benchmark - Using sglang authentication
ERROR    2025-12-02 15:18:22.%f - root:handle_uncaught_exception - Uncaught exception
Traceback (most recent call last):
  File "/home/mtkuser/spark-dev-workspace/infer-bench/bin/genai-bench", line 10, in <module>
    sys.exit(cli())
             ^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
         ^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/core.py", line 1697, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/decorators.py", line 33, in new_func
    return f(get_current_context(), *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/genai_bench/cli/cli.py", line 259, in benchmark
    tokenizer = validate_tokenizer(model_tokenizer)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/genai_bench/cli/validation.py", line 158, in validate_tokenizer
    return AutoTokenizer.from_pretrained(model_tokenizer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py", line 1109, in from_pretrained
    config = AutoConfig.from_pretrained(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py", line 1380, in from_pretrained
    raise ValueError(
ValueError: Unrecognized model in /home/mtkuser/spark-dev-workspace/dev/trtllm-bench/tiktoken. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: aimv2, aimv2_vision_model, albert, align, altclip, apertus, arcee, aria, aria_text, audio-spectrogram-transformer, autoformer, aya_vision, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, bitnet, blenderbot, blenderbot-small, blip, blip-2, blip_2_qformer, bloom, blt, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, cohere2_vision, colpali, colqwen2, conditional_detr, convbert, convnext, convnextv2, cpmant, csm, ctrl, cvt, d_fine, dab-detr, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deepseek_v2, deepseek_v3, deepseek_vl, deepseek_vl_hybrid, deformable_detr, deit, depth_anything, depth_pro, deta, detr, dia, diffllama, dinat, dinov2, dinov2_with_registers, dinov3_convnext, dinov3_vit, distilbert, doge, donut-swin, dots1, dpr, dpt, edgetam, edgetam_video, edgetam_vision_model, efficientformer, efficientloftr, efficientnet, electra, emu3, encodec, encoder-decoder, eomt, ernie, ernie4_5, ernie4_5_moe, ernie_m, esm, evolla, exaone4, falcon, falcon_h1, falcon_mamba, fastspeech2_conformer, fastspeech2_conformer_with_hifigan, flaubert, flava, flex_olmo, florence2, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, gemma3, gemma3_text, gemma3n, gemma3n_audio, gemma3n_text, gemma3n_vision, git, glm, glm4, glm4_moe, glm4v, glm4v_moe, glm4v_moe_text, glm4v_text, glpn, got_ocr2, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gpt_oss, gptj, gptsan-japanese, granite, granite_speech, granitemoe, granitemoehybrid, granitemoeshared, granitevision, graphormer, grounding-dino, groupvit, helium, hgnet_v2, hiera, hubert, hunyuan_v1_dense, hunyuan_v1_moe, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, internvl, internvl_vision, jamba, janus, jetmoe, jukebox, kosmos-2, kosmos-2.5, kyutai_speech_to_text, layoutlm, layoutlmv2, layoutlmv3, led, levit, lfm2, lfm2_vl, lightglue, lilt, llama, llama4, llama4_text, llava, llava_next, llava_next_video, llava_onevision, longcat_flash, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, metaclip_2, mgp-str, mimi, minimax, ministral, mistral, mistral3, mixtral, mlcd, mllama, mm-grounding-dino, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, modernbert, modernbert-decoder, moonshine, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmo3, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, ovis2, owlv2, owlvit, paligemma, parakeet_ctc, parakeet_encoder, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, perception_encoder, perception_lm, persimmon, phi, phi3, phi4_multimodal, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prompt_depth_anything, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_5_omni, qwen2_5_vl, qwen2_5_vl_text, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, qwen2_vl_text, qwen3, qwen3_moe, qwen3_next, qwen3_omni_moe, qwen3_vl, qwen3_vl_moe, qwen3_vl_moe_text, qwen3_vl_text, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rt_detr_v2, rwkv, sam, sam2, sam2_hiera_det_model, sam2_video, sam2_vision_model, sam_hq, sam_hq_vision_model, sam_vision_model, seamless_m4t, seamless_m4t_v2, seed_oss, segformer, seggpt, sew, sew-d, shieldgemma2, siglip, siglip2, siglip2_vision_model, siglip_vision_model, smollm3, smolvlm, smolvlm_vision, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superglue, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, t5gemma, table-transformer, tapas, textnet, time_series_transformer, timesfm, timesformer, timm_backbone, timm_wrapper, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, vaultgemma, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vitpose, vitpose_backbone, vits, vivit, vjepa2, voxtral, voxtral_encoder, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xcodec, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xlstm, xmod, yolos, yoso, zamba, zamba2, zoedepth
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - ðŸ‘‹ Welcome to genai-bench 0.0.2! I am an intelligent benchmark tool for Large Language Model.
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - Options you provided:
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - num_concurrency: (1, 2, 4, 8, 16, 32, 64, 128, 256)
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - batch_size: [1]
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - api_backend: sglang
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - api_base: http://localhost:8000
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - api_key: xxx
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - api_model_name: openai/gpt-oss-20b
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - task: text-to-text
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - max_time_per_run: 30
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - max_requests_per_run: 10
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - additional_request_params: {}
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - gcp_credentials_path: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - gcp_location: us-central1
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - gcp_project_id: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - azure_ad_token: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - azure_api_version: 2024-02-01
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - azure_deployment: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - azure_endpoint: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - aws_region: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - aws_profile: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - aws_session_token: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - aws_secret_access_key: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - aws_access_key_id: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - model_api_key: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - model_auth_type: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - region: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - security_token: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - profile: DEFAULT
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - config_file: ~/.oci/config
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - auth: user_principal
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - server_engine: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - server_version: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - server_gpu_type: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - server_gpu_count: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - model_tokenizer: ddd
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - model: ddd
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - iteration_type: num_concurrency
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - traffic_scenario: ['N(480,240)/(300,150)', 'D(100,100)', 'D(100,1000)', 'D(2000,200)', 'D(7800,200)']
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - experiment_base_dir: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - experiment_folder_name: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - dataset_path: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - dataset_prompt_column: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - dataset_image_column: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - dataset_config: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - spawn_rate: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - num_workers: 0
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - master_port: 5557
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - upload_results: False
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - namespace: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - github_repo: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - github_owner: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - github_token: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - storage_gcp_credentials_path: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - storage_gcp_project_id: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - storage_azure_sas_token: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - storage_azure_connection_string: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - storage_azure_account_key: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - storage_azure_account_name: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - storage_aws_profile: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - storage_aws_region: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - storage_aws_session_token: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - storage_aws_secret_access_key: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - storage_aws_access_key_id: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - storage_auth_type: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - storage_prefix: 
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - storage_bucket: None
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - storage_provider: oci
INFO     2025-12-02 15:19:33.%f - genai_bench.benchmark:benchmark - Using sglang authentication
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - ðŸ‘‹ Welcome to genai-bench 0.0.2! I am an intelligent benchmark tool for Large Language Model.
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - Options you provided:
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - num_concurrency: (1, 2, 4, 8, 16, 32, 64, 128, 256)
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - batch_size: [1]
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - api_backend: sglang
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - api_base: http://localhost:8000
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - api_key: xxx
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - api_model_name: openai/gpt-oss-20b
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - model_tokenizer: ~/.cache/huggingface/hub/models--openai--gpt-oss-20b/snapshots/6cee5e81ee83917806bbde320786a8fb61efebee
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - task: text-to-text
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - max_time_per_run: 30
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - max_requests_per_run: 10
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - additional_request_params: {}
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - gcp_credentials_path: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - gcp_location: us-central1
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - gcp_project_id: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - azure_ad_token: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - azure_api_version: 2024-02-01
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - azure_deployment: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - azure_endpoint: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - aws_region: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - aws_profile: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - aws_session_token: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - aws_secret_access_key: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - aws_access_key_id: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - model_api_key: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - model_auth_type: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - region: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - security_token: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - profile: DEFAULT
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - config_file: ~/.oci/config
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - auth: user_principal
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - server_engine: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - server_version: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - server_gpu_type: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - server_gpu_count: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - model: 6cee5e81ee83917806bbde320786a8fb61efebee
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - iteration_type: num_concurrency
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - traffic_scenario: ['N(480,240)/(300,150)', 'D(100,100)', 'D(100,1000)', 'D(2000,200)', 'D(7800,200)']
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - experiment_base_dir: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - experiment_folder_name: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - dataset_path: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - dataset_prompt_column: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - dataset_image_column: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - dataset_config: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - spawn_rate: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - num_workers: 0
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - master_port: 5557
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - upload_results: False
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - namespace: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - github_repo: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - github_owner: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - github_token: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - storage_gcp_credentials_path: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - storage_gcp_project_id: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - storage_azure_sas_token: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - storage_azure_connection_string: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - storage_azure_account_key: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - storage_azure_account_name: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - storage_aws_profile: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - storage_aws_region: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - storage_aws_session_token: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - storage_aws_secret_access_key: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - storage_aws_access_key_id: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - storage_auth_type: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - storage_prefix: 
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - storage_bucket: None
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - storage_provider: oci
INFO     2025-12-02 15:22:26.%f - genai_bench.benchmark:benchmark - Using sglang authentication
ERROR    2025-12-02 15:22:26.%f - root:handle_uncaught_exception - Uncaught exception
Traceback (most recent call last):
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '~/.cache/huggingface/hub/models--openai--gpt-oss-20b/snapshots/6cee5e81ee83917806bbde320786a8fb61efebee'. Use `repo_type` argument if needed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mtkuser/spark-dev-workspace/infer-bench/bin/genai-bench", line 10, in <module>
    sys.exit(cli())
             ^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
         ^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/core.py", line 1697, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/decorators.py", line 33, in new_func
    return f(get_current_context(), *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/genai_bench/cli/cli.py", line 259, in benchmark
    tokenizer = validate_tokenizer(model_tokenizer)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/genai_bench/cli/validation.py", line 162, in validate_tokenizer
    return AutoTokenizer.from_pretrained(model_tokenizer, token=hf_token)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/transformers/utils/hub.py", line 532, in cached_files
    _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision, repo_type)
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/transformers/utils/hub.py", line 143, in _get_cache_file_to_return
    resolved_file = try_to_load_from_cache(
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '~/.cache/huggingface/hub/models--openai--gpt-oss-20b/snapshots/6cee5e81ee83917806bbde320786a8fb61efebee'. Use `repo_type` argument if needed.
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - ðŸ‘‹ Welcome to genai-bench 0.0.2! I am an intelligent benchmark tool for Large Language Model.
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - Options you provided:
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - num_concurrency: (1, 2, 4, 8, 16, 32, 64, 128, 256)
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - batch_size: [1]
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - api_backend: sglang
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - api_base: http://localhost:8000
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - api_key: xxx
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - api_model_name: openai/gpt-oss-20b
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - model_tokenizer: openai/gpt-oss-20b
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - task: text-to-text
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - max_time_per_run: 30
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - max_requests_per_run: 10
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - additional_request_params: {}
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - gcp_credentials_path: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - gcp_location: us-central1
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - gcp_project_id: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - azure_ad_token: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - azure_api_version: 2024-02-01
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - azure_deployment: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - azure_endpoint: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - aws_region: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - aws_profile: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - aws_session_token: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - aws_secret_access_key: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - aws_access_key_id: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - model_api_key: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - model_auth_type: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - region: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - security_token: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - profile: DEFAULT
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - config_file: ~/.oci/config
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - auth: user_principal
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - server_engine: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - server_version: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - server_gpu_type: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - server_gpu_count: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - model: gpt-oss-20b
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - iteration_type: num_concurrency
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - traffic_scenario: ['N(480,240)/(300,150)', 'D(100,100)', 'D(100,1000)', 'D(2000,200)', 'D(7800,200)']
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - experiment_base_dir: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - experiment_folder_name: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - dataset_path: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - dataset_prompt_column: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - dataset_image_column: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - dataset_config: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - spawn_rate: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - num_workers: 0
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - master_port: 5557
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - upload_results: False
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - namespace: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - github_repo: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - github_owner: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - github_token: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - storage_gcp_credentials_path: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - storage_gcp_project_id: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - storage_azure_sas_token: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - storage_azure_connection_string: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - storage_azure_account_key: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - storage_azure_account_name: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - storage_aws_profile: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - storage_aws_region: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - storage_aws_session_token: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - storage_aws_secret_access_key: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - storage_aws_access_key_id: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - storage_auth_type: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - storage_prefix: 
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - storage_bucket: None
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - storage_provider: oci
INFO     2025-12-02 15:22:52.%f - genai_bench.benchmark:benchmark - Using sglang authentication
INFO     2025-12-02 15:22:56.%f - genai_bench.benchmark:benchmark - The average character token ratio is: 4.09673790776153
INFO     2025-12-02 15:22:56.%f - genai_bench.data.sources:_load_text_file - Loading text file: /home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/genai_bench/data/sonnet.txt
INFO     2025-12-02 15:22:56.%f - genai_bench.data.sources:_load_text_file - Loaded 84 lines from text file
INFO     2025-12-02 15:22:56.%f - genai_bench.benchmark:benchmark - This experiment will be saved in folder /home/mtkuser/spark-dev-workspace/dev/sglang-bench/sglang_text-to-text_gpt-oss-20b_20251202_152256.
INFO     2025-12-02 15:22:56.%f - genai_bench.benchmark:benchmark - Starting benchmark with concurrency=1, spawn_rate=1
INFO     2025-12-02 15:22:56.%f - locust.runners:_start - Ramping to 1 users at a rate of 1.00 per second
INFO     2025-12-02 15:22:56.%f - locust.runners:_start - All users spawned: {"OpenAIUser": 1} (1 total users)
WARNING  2025-12-02 15:23:02.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (819) differs from the number of prefill tokens returned by the sampler (752) by 67 tokens.
WARNING  2025-12-02 15:23:10.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (493) differs from the number of prefill tokens returned by the sampler (426) by 67 tokens.
WARNING  2025-12-02 15:23:13.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (95) differs from the number of prefill tokens returned by the sampler (28) by 67 tokens.
WARNING  2025-12-02 15:23:21.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (944) differs from the number of prefill tokens returned by the sampler (877) by 67 tokens.
WARNING  2025-12-02 15:23:29.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (755) differs from the number of prefill tokens returned by the sampler (688) by 67 tokens.
WARNING  2025-12-02 15:23:35.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (705) differs from the number of prefill tokens returned by the sampler (638) by 67 tokens.
WARNING  2025-12-02 15:23:40.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (383) differs from the number of prefill tokens returned by the sampler (316) by 67 tokens.
WARNING  2025-12-02 15:23:44.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (419) differs from the number of prefill tokens returned by the sampler (352) by 67 tokens.
WARNING  2025-12-02 15:23:48.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (502) differs from the number of prefill tokens returned by the sampler (435) by 67 tokens.
WARNING  2025-12-02 15:23:57.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (685) differs from the number of prefill tokens returned by the sampler (618) by 67 tokens.
INFO     2025-12-02 15:23:57.%f - genai_bench.cli.utils:manage_run_time - â© Exit the run as 10 requests have been completed.
INFO     2025-12-02 15:23:57.%f - genai_bench.benchmark:benchmark - â© Run for scenario N(480,240)/(300,150), num_concurrency 1 has finished after 61 seconds.
INFO     2025-12-02 15:23:58.%f - genai_bench.benchmark:benchmark - Starting benchmark with concurrency=2, spawn_rate=2
INFO     2025-12-02 15:23:58.%f - locust.runners:_start - Ramping to 2 users at a rate of 2.00 per second
INFO     2025-12-02 15:23:58.%f - locust.runners:_start - All users spawned: {"OpenAIUser": 2} (2 total users)
WARNING  2025-12-02 15:24:04.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (525) differs from the number of prefill tokens returned by the sampler (458) by 67 tokens.
WARNING  2025-12-02 15:24:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (447) differs from the number of prefill tokens returned by the sampler (380) by 67 tokens.
WARNING  2025-12-02 15:24:17.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (409) differs from the number of prefill tokens returned by the sampler (342) by 67 tokens.
WARNING  2025-12-02 15:24:24.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (359) differs from the number of prefill tokens returned by the sampler (292) by 67 tokens.
WARNING  2025-12-02 15:24:24.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (458) differs from the number of prefill tokens returned by the sampler (391) by 67 tokens.
WARNING  2025-12-02 15:24:27.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (601) differs from the number of prefill tokens returned by the sampler (534) by 67 tokens.
WARNING  2025-12-02 15:24:27.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (711) differs from the number of prefill tokens returned by the sampler (644) by 67 tokens.
WARNING  2025-12-02 15:24:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (326) differs from the number of prefill tokens returned by the sampler (259) by 67 tokens.
WARNING  2025-12-02 15:24:37.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (652) differs from the number of prefill tokens returned by the sampler (585) by 67 tokens.
WARNING  2025-12-02 15:24:39.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (561) differs from the number of prefill tokens returned by the sampler (494) by 67 tokens.
INFO     2025-12-02 15:24:39.%f - genai_bench.cli.utils:manage_run_time - â© Exit the run as 10 requests have been completed.
INFO     2025-12-02 15:24:39.%f - genai_bench.benchmark:benchmark - â© Run for scenario N(480,240)/(300,150), num_concurrency 2 has finished after 41 seconds.
INFO     2025-12-02 15:24:40.%f - genai_bench.benchmark:benchmark - Starting benchmark with concurrency=4, spawn_rate=4
INFO     2025-12-02 15:24:40.%f - locust.runners:_start - Ramping to 4 users at a rate of 4.00 per second
INFO     2025-12-02 15:24:40.%f - locust.runners:_start - All users spawned: {"OpenAIUser": 4} (4 total users)
WARNING  2025-12-02 15:24:49.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (381) differs from the number of prefill tokens returned by the sampler (314) by 67 tokens.
WARNING  2025-12-02 15:24:53.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (628) differs from the number of prefill tokens returned by the sampler (561) by 67 tokens.
WARNING  2025-12-02 15:24:55.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (456) differs from the number of prefill tokens returned by the sampler (389) by 67 tokens.
WARNING  2025-12-02 15:24:59.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (472) differs from the number of prefill tokens returned by the sampler (405) by 67 tokens.
WARNING  2025-12-02 15:25:03.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (337) differs from the number of prefill tokens returned by the sampler (270) by 67 tokens.
WARNING  2025-12-02 15:25:04.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (140) differs from the number of prefill tokens returned by the sampler (73) by 67 tokens.
WARNING  2025-12-02 15:25:06.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (534) differs from the number of prefill tokens returned by the sampler (467) by 67 tokens.
WARNING  2025-12-02 15:25:07.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (684) differs from the number of prefill tokens returned by the sampler (617) by 67 tokens.
WARNING  2025-12-02 15:25:14.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (337) differs from the number of prefill tokens returned by the sampler (270) by 67 tokens.
WARNING  2025-12-02 15:25:17.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (350) differs from the number of prefill tokens returned by the sampler (283) by 67 tokens.
INFO     2025-12-02 15:25:17.%f - genai_bench.cli.utils:manage_run_time - â© Exit the run as 10 requests have been completed.
INFO     2025-12-02 15:25:17.%f - genai_bench.benchmark:benchmark - â© Run for scenario N(480,240)/(300,150), num_concurrency 4 has finished after 37 seconds.
INFO     2025-12-02 15:25:18.%f - genai_bench.benchmark:benchmark - Starting benchmark with concurrency=8, spawn_rate=8
INFO     2025-12-02 15:25:18.%f - locust.runners:_start - Ramping to 8 users at a rate of 8.00 per second
INFO     2025-12-02 15:25:18.%f - locust.runners:_start - All users spawned: {"OpenAIUser": 8} (8 total users)
WARNING  2025-12-02 15:25:30.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (1003) differs from the number of prefill tokens returned by the sampler (936) by 67 tokens.
WARNING  2025-12-02 15:25:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (161) differs from the number of prefill tokens returned by the sampler (94) by 67 tokens.
WARNING  2025-12-02 15:25:39.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (622) differs from the number of prefill tokens returned by the sampler (555) by 67 tokens.
WARNING  2025-12-02 15:25:44.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (586) differs from the number of prefill tokens returned by the sampler (519) by 67 tokens.
WARNING  2025-12-02 15:25:46.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (825) differs from the number of prefill tokens returned by the sampler (758) by 67 tokens.
WARNING  2025-12-02 15:25:48.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (571) differs from the number of prefill tokens returned by the sampler (504) by 67 tokens.
WARNING  2025-12-02 15:25:52.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (376) differs from the number of prefill tokens returned by the sampler (309) by 67 tokens.
WARNING  2025-12-02 15:25:55.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (598) differs from the number of prefill tokens returned by the sampler (531) by 67 tokens.
WARNING  2025-12-02 15:25:56.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (808) differs from the number of prefill tokens returned by the sampler (741) by 67 tokens.
WARNING  2025-12-02 15:25:58.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (685) differs from the number of prefill tokens returned by the sampler (618) by 67 tokens.
WARNING  2025-12-02 15:25:59.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (554) differs from the number of prefill tokens returned by the sampler (487) by 67 tokens.
INFO     2025-12-02 15:25:59.%f - genai_bench.cli.utils:manage_run_time - â© Exit the run as 11 requests have been completed.
INFO     2025-12-02 15:25:59.%f - genai_bench.benchmark:benchmark - â© Run for scenario N(480,240)/(300,150), num_concurrency 8 has finished after 41 seconds.
INFO     2025-12-02 15:26:00.%f - genai_bench.benchmark:benchmark - Starting benchmark with concurrency=16, spawn_rate=16
INFO     2025-12-02 15:26:00.%f - locust.runners:_start - Ramping to 16 users at a rate of 16.00 per second
INFO     2025-12-02 15:26:00.%f - locust.runners:_start - All users spawned: {"OpenAIUser": 16} (16 total users)
WARNING  2025-12-02 15:26:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (592) differs from the number of prefill tokens returned by the sampler (525) by 67 tokens.
WARNING  2025-12-02 15:26:19.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (736) differs from the number of prefill tokens returned by the sampler (669) by 67 tokens.
WARNING  2025-12-02 15:26:24.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (68) differs from the number of prefill tokens returned by the sampler (1) by 67 tokens.
WARNING  2025-12-02 15:26:26.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (1050) differs from the number of prefill tokens returned by the sampler (983) by 67 tokens.
WARNING  2025-12-02 15:26:28.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (635) differs from the number of prefill tokens returned by the sampler (568) by 67 tokens.
WARNING  2025-12-02 15:26:29.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (438) differs from the number of prefill tokens returned by the sampler (371) by 67 tokens.
WARNING  2025-12-02 15:26:30.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (522) differs from the number of prefill tokens returned by the sampler (455) by 67 tokens.
WARNING  2025-12-02 15:26:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (679) differs from the number of prefill tokens returned by the sampler (612) by 67 tokens.
WARNING  2025-12-02 15:26:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (888) differs from the number of prefill tokens returned by the sampler (821) by 67 tokens.
WARNING  2025-12-02 15:26:37.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (658) differs from the number of prefill tokens returned by the sampler (591) by 67 tokens.
INFO     2025-12-02 15:26:37.%f - genai_bench.cli.utils:manage_run_time - â© Exit the run as 10 requests have been completed.
INFO     2025-12-02 15:26:37.%f - genai_bench.benchmark:benchmark - â© Run for scenario N(480,240)/(300,150), num_concurrency 16 has finished after 37 seconds.
INFO     2025-12-02 15:26:38.%f - genai_bench.benchmark:benchmark - Starting benchmark with concurrency=32, spawn_rate=32
INFO     2025-12-02 15:26:38.%f - locust.runners:_start - Ramping to 32 users at a rate of 32.00 per second
INFO     2025-12-02 15:26:38.%f - locust.runners:_start - All users spawned: {"OpenAIUser": 32} (32 total users)
WARNING  2025-12-02 15:27:10.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (663) differs from the number of prefill tokens returned by the sampler (596) by 67 tokens.
WARNING  2025-12-02 15:27:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (1056) differs from the number of prefill tokens returned by the sampler (989) by 67 tokens.
WARNING  2025-12-02 15:27:16.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (537) differs from the number of prefill tokens returned by the sampler (470) by 67 tokens.
WARNING  2025-12-02 15:27:16.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (365) differs from the number of prefill tokens returned by the sampler (298) by 67 tokens.
WARNING  2025-12-02 15:27:18.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (133) differs from the number of prefill tokens returned by the sampler (66) by 67 tokens.
WARNING  2025-12-02 15:27:19.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (428) differs from the number of prefill tokens returned by the sampler (361) by 67 tokens.
WARNING  2025-12-02 15:27:21.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (670) differs from the number of prefill tokens returned by the sampler (603) by 67 tokens.
WARNING  2025-12-02 15:27:22.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (952) differs from the number of prefill tokens returned by the sampler (885) by 67 tokens.
WARNING  2025-12-02 15:27:22.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (346) differs from the number of prefill tokens returned by the sampler (279) by 67 tokens.
WARNING  2025-12-02 15:27:25.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (711) differs from the number of prefill tokens returned by the sampler (644) by 67 tokens.
INFO     2025-12-02 15:27:25.%f - genai_bench.cli.utils:manage_run_time - â© Exit the run as 10 requests have been completed.
INFO     2025-12-02 15:27:25.%f - genai_bench.benchmark:benchmark - â© Run for scenario N(480,240)/(300,150), num_concurrency 32 has finished after 47 seconds.
INFO     2025-12-02 15:27:26.%f - genai_bench.benchmark:benchmark - Starting benchmark with concurrency=64, spawn_rate=64
INFO     2025-12-02 15:27:26.%f - locust.runners:_start - Ramping to 64 users at a rate of 64.00 per second
INFO     2025-12-02 15:27:26.%f - locust.runners:_start - All users spawned: {"OpenAIUser": 64} (64 total users)
WARNING  2025-12-02 15:28:29.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (688) differs from the number of prefill tokens returned by the sampler (621) by 67 tokens.
WARNING  2025-12-02 15:28:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (603) differs from the number of prefill tokens returned by the sampler (536) by 67 tokens.
WARNING  2025-12-02 15:28:32.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (399) differs from the number of prefill tokens returned by the sampler (332) by 67 tokens.
WARNING  2025-12-02 15:28:32.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (566) differs from the number of prefill tokens returned by the sampler (499) by 67 tokens.
WARNING  2025-12-02 15:28:36.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (928) differs from the number of prefill tokens returned by the sampler (861) by 67 tokens.
WARNING  2025-12-02 15:28:37.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (501) differs from the number of prefill tokens returned by the sampler (434) by 67 tokens.
WARNING  2025-12-02 15:28:39.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (645) differs from the number of prefill tokens returned by the sampler (578) by 67 tokens.
WARNING  2025-12-02 15:28:42.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (637) differs from the number of prefill tokens returned by the sampler (570) by 67 tokens.
WARNING  2025-12-02 15:28:45.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (351) differs from the number of prefill tokens returned by the sampler (284) by 67 tokens.
WARNING  2025-12-02 15:28:46.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (809) differs from the number of prefill tokens returned by the sampler (742) by 67 tokens.
WARNING  2025-12-02 15:28:46.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (757) differs from the number of prefill tokens returned by the sampler (690) by 67 tokens.
INFO     2025-12-02 15:28:47.%f - genai_bench.cli.utils:manage_run_time - â© Exit the run as 11 requests have been completed.
INFO     2025-12-02 15:28:47.%f - genai_bench.benchmark:benchmark - â© Run for scenario N(480,240)/(300,150), num_concurrency 64 has finished after 80 seconds.
INFO     2025-12-02 15:28:48.%f - genai_bench.benchmark:benchmark - Starting benchmark with concurrency=128, spawn_rate=128
WARNING  2025-12-02 15:28:48.%f - locust.runners:start - Your selected spawn rate is very high (>100), and this is known to sometimes cause issues. Do you really need to ramp up that fast?
INFO     2025-12-02 15:28:48.%f - locust.runners:_start - Ramping to 128 users at a rate of 128.00 per second
INFO     2025-12-02 15:28:48.%f - locust.runners:_start - All users spawned: {"OpenAIUser": 128} (128 total users)
WARNING  2025-12-02 15:30:41.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (638) differs from the number of prefill tokens returned by the sampler (571) by 67 tokens.
WARNING  2025-12-02 15:30:41.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (739) differs from the number of prefill tokens returned by the sampler (672) by 67 tokens.
WARNING  2025-12-02 15:30:47.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (413) differs from the number of prefill tokens returned by the sampler (346) by 67 tokens.
WARNING  2025-12-02 15:30:47.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (385) differs from the number of prefill tokens returned by the sampler (318) by 67 tokens.
WARNING  2025-12-02 15:30:48.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (641) differs from the number of prefill tokens returned by the sampler (574) by 67 tokens.
WARNING  2025-12-02 15:30:53.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:30:53.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (731) differs from the number of prefill tokens returned by the sampler (664) by 67 tokens.
WARNING  2025-12-02 15:30:57.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (619) differs from the number of prefill tokens returned by the sampler (552) by 67 tokens.
WARNING  2025-12-02 15:30:57.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (482) differs from the number of prefill tokens returned by the sampler (415) by 67 tokens.
WARNING  2025-12-02 15:30:59.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (600) differs from the number of prefill tokens returned by the sampler (533) by 67 tokens.
WARNING  2025-12-02 15:31:00.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (390) differs from the number of prefill tokens returned by the sampler (323) by 67 tokens.
INFO     2025-12-02 15:31:00.%f - genai_bench.cli.utils:manage_run_time - â© Exit the run as 11 requests have been completed.
INFO     2025-12-02 15:31:00.%f - genai_bench.benchmark:benchmark - â© Run for scenario N(480,240)/(300,150), num_concurrency 128 has finished after 132 seconds.
INFO     2025-12-02 15:31:01.%f - genai_bench.benchmark:benchmark - Starting benchmark with concurrency=256, spawn_rate=256
WARNING  2025-12-02 15:31:01.%f - locust.runners:start - Your selected spawn rate is very high (>100), and this is known to sometimes cause issues. Do you really need to ramp up that fast?
INFO     2025-12-02 15:31:01.%f - locust.runners:_start - Ramping to 256 users at a rate of 256.00 per second
INFO     2025-12-02 15:31:01.%f - locust.runners:_start - All users spawned: {"OpenAIUser": 256} (256 total users)
WARNING  2025-12-02 15:31:01.%f - genai_bench.sampling.text:_check_discrepancy - ðŸš¨ Sampling discrepancy detected: num_input_tokens=1141, num_prefill_tokens=1120, discrepancy=21
WARNING  2025-12-02 15:34:44.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (630) differs from the number of prefill tokens returned by the sampler (563) by 67 tokens.
WARNING  2025-12-02 15:34:44.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (723) differs from the number of prefill tokens returned by the sampler (656) by 67 tokens.
WARNING  2025-12-02 15:34:44.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (524) differs from the number of prefill tokens returned by the sampler (457) by 67 tokens.
WARNING  2025-12-02 15:34:44.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (420) differs from the number of prefill tokens returned by the sampler (353) by 67 tokens.
WARNING  2025-12-02 15:34:44.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (792) differs from the number of prefill tokens returned by the sampler (725) by 67 tokens.
WARNING  2025-12-02 15:34:44.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (1106) differs from the number of prefill tokens returned by the sampler (1039) by 67 tokens.
WARNING  2025-12-02 15:34:51.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (452) differs from the number of prefill tokens returned by the sampler (385) by 67 tokens.
WARNING  2025-12-02 15:34:55.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (675) differs from the number of prefill tokens returned by the sampler (608) by 67 tokens.
WARNING  2025-12-02 15:34:56.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (322) differs from the number of prefill tokens returned by the sampler (255) by 67 tokens.
WARNING  2025-12-02 15:34:57.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (205) differs from the number of prefill tokens returned by the sampler (138) by 67 tokens.
INFO     2025-12-02 15:34:57.%f - genai_bench.cli.utils:manage_run_time - â© Exit the run as 10 requests have been completed.
INFO     2025-12-02 15:34:57.%f - genai_bench.benchmark:benchmark - â© Run for scenario N(480,240)/(300,150), num_concurrency 256 has finished after 236 seconds.
INFO     2025-12-02 15:34:58.%f - genai_bench.analysis.plot_report:plot_single_scenario_inference_speed_vs_throughput - ðŸŽ¨ Saving interim plot: /home/mtkuser/spark-dev-workspace/dev/sglang-bench/sglang_text-to-text_gpt-oss-20b_20251202_152256/interim_N480_240_300_150_output_speed_vs_throughput.png
INFO     2025-12-02 15:34:58.%f - genai_bench.benchmark:benchmark - Starting benchmark with concurrency=1, spawn_rate=1
INFO     2025-12-02 15:34:58.%f - locust.runners:_start - Ramping to 1 users at a rate of 1.00 per second
INFO     2025-12-02 15:34:58.%f - locust.runners:_start - All users spawned: {"OpenAIUser": 1} (1 total users)
WARNING  2025-12-02 15:35:01.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:35:02.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:35:04.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:35:05.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:35:07.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:35:08.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (168) differs from the number of prefill tokens returned by the sampler (101) by 67 tokens.
WARNING  2025-12-02 15:35:10.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:11.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (168) differs from the number of prefill tokens returned by the sampler (101) by 67 tokens.
WARNING  2025-12-02 15:35:13.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:14.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
INFO     2025-12-02 15:35:15.%f - genai_bench.cli.utils:manage_run_time - â© Exit the run as 10 requests have been completed.
INFO     2025-12-02 15:35:15.%f - genai_bench.benchmark:benchmark - â© Run for scenario D(100,100), num_concurrency 1 has finished after 17 seconds.
INFO     2025-12-02 15:35:16.%f - genai_bench.benchmark:benchmark - Starting benchmark with concurrency=2, spawn_rate=2
INFO     2025-12-02 15:35:16.%f - locust.runners:_start - Ramping to 2 users at a rate of 2.00 per second
INFO     2025-12-02 15:35:16.%f - locust.runners:_start - All users spawned: {"OpenAIUser": 2} (2 total users)
WARNING  2025-12-02 15:35:18.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:18.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:35:20.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:35:20.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:22.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:35:22.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:35:24.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:24.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (163) differs from the number of prefill tokens returned by the sampler (96) by 67 tokens.
WARNING  2025-12-02 15:35:26.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:35:26.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
INFO     2025-12-02 15:35:26.%f - genai_bench.cli.utils:manage_run_time - â© Exit the run as 10 requests have been completed.
INFO     2025-12-02 15:35:26.%f - genai_bench.benchmark:benchmark - â© Run for scenario D(100,100), num_concurrency 2 has finished after 10 seconds.
INFO     2025-12-02 15:35:27.%f - genai_bench.benchmark:benchmark - Starting benchmark with concurrency=4, spawn_rate=4
INFO     2025-12-02 15:35:27.%f - locust.runners:_start - Ramping to 4 users at a rate of 4.00 per second
INFO     2025-12-02 15:35:27.%f - locust.runners:_start - All users spawned: {"OpenAIUser": 4} (4 total users)
WARNING  2025-12-02 15:35:30.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (163) differs from the number of prefill tokens returned by the sampler (96) by 67 tokens.
WARNING  2025-12-02 15:35:30.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:35:30.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:35:30.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:35:33.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:35:33.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:35:33.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:33.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:35:35.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:35.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:35:35.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:35.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
INFO     2025-12-02 15:35:35.%f - genai_bench.cli.utils:manage_run_time - â© Exit the run as 12 requests have been completed.
INFO     2025-12-02 15:35:35.%f - genai_bench.benchmark:benchmark - â© Run for scenario D(100,100), num_concurrency 4 has finished after 8 seconds.
INFO     2025-12-02 15:35:36.%f - genai_bench.benchmark:benchmark - Starting benchmark with concurrency=8, spawn_rate=8
INFO     2025-12-02 15:35:36.%f - locust.runners:_start - Ramping to 8 users at a rate of 8.00 per second
INFO     2025-12-02 15:35:36.%f - locust.runners:_start - All users spawned: {"OpenAIUser": 8} (8 total users)
WARNING  2025-12-02 15:35:42.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:42.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:42.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:42.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:35:42.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:35:42.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:35:42.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:42.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:47.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:35:47.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:35:47.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:35:47.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:35:47.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:47.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:47.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:47.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
INFO     2025-12-02 15:35:47.%f - genai_bench.cli.utils:manage_run_time - â© Exit the run as 16 requests have been completed.
INFO     2025-12-02 15:35:47.%f - genai_bench.benchmark:benchmark - â© Run for scenario D(100,100), num_concurrency 8 has finished after 11 seconds.
INFO     2025-12-02 15:35:48.%f - genai_bench.benchmark:benchmark - Starting benchmark with concurrency=16, spawn_rate=16
INFO     2025-12-02 15:35:48.%f - locust.runners:_start - Ramping to 16 users at a rate of 16.00 per second
INFO     2025-12-02 15:35:48.%f - locust.runners:_start - All users spawned: {"OpenAIUser": 16} (16 total users)
WARNING  2025-12-02 15:35:56.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:56.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:56.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:56.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:56.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (163) differs from the number of prefill tokens returned by the sampler (96) by 67 tokens.
WARNING  2025-12-02 15:35:56.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:35:56.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:56.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:35:56.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:35:56.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:35:56.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:35:56.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:35:56.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:35:56.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:35:56.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:35:56.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
INFO     2025-12-02 15:35:56.%f - genai_bench.cli.utils:manage_run_time - â© Exit the run as 16 requests have been completed.
INFO     2025-12-02 15:35:56.%f - genai_bench.benchmark:benchmark - â© Run for scenario D(100,100), num_concurrency 16 has finished after 8 seconds.
INFO     2025-12-02 15:35:57.%f - genai_bench.benchmark:benchmark - Starting benchmark with concurrency=32, spawn_rate=32
INFO     2025-12-02 15:35:57.%f - locust.runners:_start - Ramping to 32 users at a rate of 32.00 per second
INFO     2025-12-02 15:35:57.%f - locust.runners:_start - All users spawned: {"OpenAIUser": 32} (32 total users)
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (168) differs from the number of prefill tokens returned by the sampler (101) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (163) differs from the number of prefill tokens returned by the sampler (96) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (163) differs from the number of prefill tokens returned by the sampler (96) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:36:09.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
INFO     2025-12-02 15:36:09.%f - genai_bench.cli.utils:manage_run_time - â© Exit the run as 32 requests have been completed.
INFO     2025-12-02 15:36:09.%f - genai_bench.benchmark:benchmark - â© Run for scenario D(100,100), num_concurrency 32 has finished after 12 seconds.
INFO     2025-12-02 15:36:10.%f - genai_bench.benchmark:benchmark - Starting benchmark with concurrency=64, spawn_rate=64
INFO     2025-12-02 15:36:10.%f - locust.runners:_start - Ramping to 64 users at a rate of 64.00 per second
INFO     2025-12-02 15:36:10.%f - locust.runners:_start - All users spawned: {"OpenAIUser": 64} (64 total users)
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (163) differs from the number of prefill tokens returned by the sampler (96) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (168) differs from the number of prefill tokens returned by the sampler (101) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (163) differs from the number of prefill tokens returned by the sampler (96) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (168) differs from the number of prefill tokens returned by the sampler (101) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (163) differs from the number of prefill tokens returned by the sampler (96) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (163) differs from the number of prefill tokens returned by the sampler (96) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (163) differs from the number of prefill tokens returned by the sampler (96) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:36:34.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
INFO     2025-12-02 15:36:34.%f - genai_bench.cli.utils:manage_run_time - â© Exit the run as 64 requests have been completed.
INFO     2025-12-02 15:36:35.%f - genai_bench.benchmark:benchmark - â© Run for scenario D(100,100), num_concurrency 64 has finished after 24 seconds.
INFO     2025-12-02 15:36:36.%f - genai_bench.benchmark:benchmark - Starting benchmark with concurrency=128, spawn_rate=128
WARNING  2025-12-02 15:36:36.%f - locust.runners:start - Your selected spawn rate is very high (>100), and this is known to sometimes cause issues. Do you really need to ramp up that fast?
INFO     2025-12-02 15:36:36.%f - locust.runners:_start - Ramping to 128 users at a rate of 128.00 per second
INFO     2025-12-02 15:36:36.%f - locust.runners:_start - All users spawned: {"OpenAIUser": 128} (128 total users)
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (168) differs from the number of prefill tokens returned by the sampler (101) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (168) differs from the number of prefill tokens returned by the sampler (101) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (163) differs from the number of prefill tokens returned by the sampler (96) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (168) differs from the number of prefill tokens returned by the sampler (101) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:37:15.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
INFO     2025-12-02 15:37:16.%f - genai_bench.cli.utils:manage_run_time - â© Exit the run as 128 requests have been completed.
INFO     2025-12-02 15:37:16.%f - genai_bench.benchmark:benchmark - â© Run for scenario D(100,100), num_concurrency 128 has finished after 40 seconds.
INFO     2025-12-02 15:37:17.%f - genai_bench.benchmark:benchmark - Starting benchmark with concurrency=256, spawn_rate=256
WARNING  2025-12-02 15:37:17.%f - locust.runners:start - Your selected spawn rate is very high (>100), and this is known to sometimes cause issues. Do you really need to ramp up that fast?
INFO     2025-12-02 15:37:17.%f - locust.runners:_start - Ramping to 256 users at a rate of 256.00 per second
INFO     2025-12-02 15:37:17.%f - locust.runners:_start - All users spawned: {"OpenAIUser": 256} (256 total users)
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (163) differs from the number of prefill tokens returned by the sampler (96) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (168) differs from the number of prefill tokens returned by the sampler (101) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (168) differs from the number of prefill tokens returned by the sampler (101) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (163) differs from the number of prefill tokens returned by the sampler (96) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (168) differs from the number of prefill tokens returned by the sampler (101) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (168) differs from the number of prefill tokens returned by the sampler (101) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (163) differs from the number of prefill tokens returned by the sampler (96) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (165) differs from the number of prefill tokens returned by the sampler (98) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (164) differs from the number of prefill tokens returned by the sampler (97) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (166) differs from the number of prefill tokens returned by the sampler (99) by 67 tokens.
WARNING  2025-12-02 15:38:31.%f - genai_bench.user.openai_user:_get_usage_info - Significant difference detected in prompt tokens: The number of prompt tokens processed by the model server (167) differs from the number of prefill tokens returned by the sampler (100) by 67 tokens.
INFO     2025-12-02 15:38:32.%f - genai_bench.cli.utils:manage_run_time - â© Exit the run as 256 requests have been completed.
INFO     2025-12-02 15:38:32.%f - genai_bench.benchmark:benchmark - â© Run for scenario D(100,100), num_concurrency 256 has finished after 75 seconds.
INFO     2025-12-02 15:38:33.%f - genai_bench.analysis.plot_report:plot_single_scenario_inference_speed_vs_throughput - ðŸŽ¨ Saving interim plot: /home/mtkuser/spark-dev-workspace/dev/sglang-bench/sglang_text-to-text_gpt-oss-20b_20251202_152256/interim_D100_100_output_speed_vs_throughput.png
INFO     2025-12-02 15:38:33.%f - genai_bench.benchmark:benchmark - Starting benchmark with concurrency=1, spawn_rate=1
INFO     2025-12-02 15:38:33.%f - locust.runners:_start - Ramping to 1 users at a rate of 1.00 per second
INFO     2025-12-02 15:38:33.%f - locust.runners:_start - All users spawned: {"OpenAIUser": 1} (1 total users)
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 500, message: Response ended prematurely.
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
WARNING  2025-12-02 15:38:42.%f - genai_bench.user.base_user:collect_metrics - Received error response from server. Error code: 503, message: Connection error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).
INFO     2025-12-02 15:38:42.%f - genai_bench.cli.utils:manage_run_time - â© Exit the run as 88 requests have been completed.
ERROR    2025-12-02 15:38:42.%f - root:handle_uncaught_exception - Uncaught exception
Traceback (most recent call last):
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/genai_bench/cli/cli.py", line 429, in benchmark
    aggregated_metrics_collector.aggregate_metrics_data(
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/genai_bench/metrics/aggregated_metrics_collector.py", line 152, in aggregate_metrics_data
    raise ValueError(
ValueError: No values found for metric 'ttft'. This should never happen!

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/mtkuser/spark-dev-workspace/infer-bench/bin/genai-bench", line 10, in <module>
    sys.exit(cli())
             ^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
         ^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/core.py", line 1697, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/click/decorators.py", line 33, in new_func
    return f(get_current_context(), *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mtkuser/spark-dev-workspace/infer-bench/lib/python3.12/site-packages/genai_bench/cli/cli.py", line 441, in benchmark
    raise ValueError(
ValueError: No values found for metric 'ttft'. This should never happen! Please check out debug_for_run_D100_1000_1.json to see the detailed individual metrics!
